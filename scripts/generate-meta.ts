#!/usr/bin/env ts-node
/**
 * Generate sitemap.xml and robots.txt dynamically for GitHub Pages deployment.
 * - Uses a static route manifest (can extend to auto-scan later)
 * - Writes into apps/demo-app/public prior to build
 */
import { readFileSync, writeFileSync } from 'fs';
import { dirname, join } from 'path';
import { fileURLToPath } from 'url';

const __dirname = dirname(fileURLToPath(import.meta.url));

const PUBLIC_DIR = join(__dirname, '../apps/demo-app/public');
const BASE_URL = 'https://markhazleton.github.io/tailwind-demo';
const today = new Date().toISOString().split('T')[0];

// Central route manifest (could be generated by scanning page exports)
const routes: { path: string; priority: number; changefreq: string }[] = [
  { path: '/', priority: 1.0, changefreq: 'weekly' },
  { path: '/design-system', priority: 0.85, changefreq: 'monthly' },
  { path: '/animations', priority: 0.85, changefreq: 'monthly' },
  { path: '/dashboard', priority: 0.8, changefreq: 'monthly' },
  { path: '/ecommerce', priority: 0.75, changefreq: 'monthly' },
  { path: '/marketing', priority: 0.75, changefreq: 'monthly' },
  { path: '/demos', priority: 0.7, changefreq: 'monthly' },
  { path: '/analytics', priority: 0.65, changefreq: 'monthly' },
  { path: '/users', priority: 0.65, changefreq: 'monthly' },
  { path: '/settings', priority: 0.6, changefreq: 'monthly' },
];

const sitemap = `<?xml version="1.0" encoding="UTF-8"?>\n<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">\n${routes
  .map(
    r =>
      `  <url>\n    <loc>${BASE_URL}${r.path}</loc>\n    <lastmod>${today}</lastmod>\n    <changefreq>${r.changefreq}</changefreq>\n    <priority>${r.priority.toFixed(2)}</priority>\n  </url>`
  )
  .join('\n')}\n</urlset>\n`;

writeFileSync(join(PUBLIC_DIR, 'sitemap.xml'), sitemap, 'utf8');

// Update robots.txt last generated comment
const robotsPath = join(PUBLIC_DIR, 'robots.txt');
let robots = '';
try {
  robots = readFileSync(robotsPath, 'utf8');
} catch {
  robots = 'User-agent: *\nAllow: /\n';
}

if (!robots.includes('Sitemap:')) {
  robots += `\nSitemap: ${BASE_URL}/sitemap.xml\n`;
}

// Remove previous generated marker
robots = robots.replace(/# Generated:.*/g, '').trim();
robots += `\n\n# Generated: ${today}`;

writeFileSync(robotsPath, robots + '\n', 'utf8');

console.warn('Generated sitemap.xml & updated robots.txt');
